\subsection{Threads Domain}

We encoded a simple assembly-like abstract machine with a fork/join primitive as a planning domain, which we call the ``threads'' domain.
Its predicates are used to indicate values of data and to indicate a program's instruction sequence.
Its actions represent the evaluation rules for the language's instruction set.

Some predicates express data:
\begin{itemize}
	\item \texttt{value ?name ?value} indicates the value of a variable with a given name.
	\item \texttt{succ ?n ?m} indicates the structure of integers. We were unable to find a planner that supported built-in integers, so for each problem we defined a sequence of literals (\texttt{n0}, \texttt{n1}, etc) and used the successor relation to abstractly express (very) simple arithmetic.
\end{itemize}

We now discuss the specifics of selected instructions. In the domain definition, each instruction has both a predicate (to be used in the representation of a program's instruction stream) and an action (which allows the planner to change the machine state when it encounters).

\begin{itemize}
	\item \texttt{set ?me ?next ?name ?value} - Assigns a value to a variable. \texttt{me} is the label for this instruction (all instructions share this pattern), \texttt{next} is the label of the next instruction to evaluate after this one (most instructions share this pattern). The increment, decrement, load, atomic-exchange, and atomic-add instructions are similar.
	\item \texttt{branch ?me ?name ?iftrue ?iffalse} - Flow control. Instead of \texttt{next}, there are two next instructions, selected between depending whether \texttt{name} is \texttt{n0}.
	\item \texttt{exit ?me} - Terminates execution of the current thread (or program).
	\item \texttt{fork ?me ?next ?child1 ?child2} - Runs \texttt{child1} and \texttt{child2} to completion (both must \texttt{exit}), and then advances to \texttt{next}.
\end{itemize}

Finally, a special predicate indicates the program counter (instruction pointer):
\begin{itemize}
	\item \texttt{eval ?instruction ?out} - The first argument is the label associated with the next instruction to be executed. Its second argument is the ``destination'' label, a special label used to identify which threads have terminated. There will be as many \texttt{eval} tokens as currently-running threads.
\end{itemize}

\subsection{Warmup: Data Races}

Our first test case for the threads domain was to demonstrate a simple data race between two threads. We show how two interleaving threads attempting to increment a shared variable can produce nondeterministically different results. The initial state of the planning problem expresses the following program (or various elaborations thereof, such as placing the accesses in a loop or adding a third thread):

	\begin{center}
	\begin{tabular}{ll}
	\multicolumn{2}{c}{\texttt{fork(thread1, thread2);}} \\
	& \\
	\texttt{thread1() \{} & \texttt{thread2() \{} \\
	\texttt{~~~~temp0 = x;\qquad} & \texttt{~~~~temp1 = x;} \\
	\texttt{~~~~temp0++;} & \texttt{~~~~temp1++;} \\
	\texttt{~~~~x = temp0;} & \texttt{~~~~x = temp1;} \\
	\texttt{\}} & \texttt{\}} \\
	\end{tabular}
	\end{center}

In this example, possible values for \texttt{x} at the end are 1 and 2. The problems with filenames starting in \texttt{prob1} demonstrate this problem; those with filenames starting in \texttt{prob2} and \texttt{prob3} are elaborations on it.

\subsection{Verifying Synchronisation Algorithms}

We next explored several different algorithms for {\em synchronisation} -- the problem of protecting designated ``critical sections'' of execution from unsafe concurrent access. Mutual exclusion algorithms are characterised by three properties: {\em mutual exclusion}, {\em bounded waiting}, and {\em progress}~\cite{de0u}. We next discuss how planners helped us verify these properties.

\begin{enumerate}
	\item {\bf Mutual Exclusion.} An algorithm that provides mutual exclusion does not allow multiple threads to be executing in the critical section simultaneously.
	To ensure that an algorithm provides mutual exclusion, we write programs of the following form, in which both threads modify a \texttt{num\_in\_section} counter to indicate when they're in the critical section:
	\begin{center}
	\begin{tabular}{ll}
	\multicolumn{2}{c}{\texttt{num\_in\_section = 0;~~~~~}} \\
	\multicolumn{2}{c}{\texttt{fork(thread1, thread2);}} \\
	& \\
	\texttt{thread1() \{} & \texttt{thread2() \{} \\
	\texttt{~~~~while (true) \{} & \texttt{~~~~while (true) \{} \\
	\texttt{~~~~~~~~\em lock\_sequence();} & \texttt{~~~~~~~~\em lock\_sequence();} \\
	\texttt{~~~~~~~~num\_in\_section++;} & \texttt{~~~~~~~~num\_in\_section++;} \\
	\texttt{~~~~~~~~num\_in\_section--;} & \texttt{~~~~~~~~num\_in\_section--;} \\
	\texttt{~~~~~~~~\em unlock\_sequence();\qquad} & \texttt{~~~~~~~~\em unlock\_sequence();} \\
	\texttt{~~~~\}} & \texttt{~~~~\}} \\
	\texttt{\}} & \texttt{\}} \\
	\end{tabular}
	\end{center}
	We then set the goal statement to be \texttt{num\_in\_section == 2}. When a complete planner cannot plan for this fact, it guarantees that no execution interleaving exists in which both threads are in the section at once -- in other words, that mutual exclusion is satisfied.

	We added the infinite loop in each thread's body to test the unlock sequence as well as the lock sequence, to account for the possibility that a broken algorithm might require multiple iterations before failing. One particular strength of planners shines here; namely, their ability to deal with cyclic state spaces. In the blocks world, no planner worth its salt would get stuck evaluating the infinite plan ``pick up block A, stack A on B, pick up block A, \dots''; likewise, here the planners can easily cope with the infinite loops in each thread.
	\item {\bf Bounded Waiting.} An algorithm that provides bounded waiting does not allow any thread to be ``starved'' while waiting for the lock; that is, once a thread has expressed interest in acquiring the lock, there exists some finite number $N$ such that other threads can perform no more than $N$ subsequent operations on the lock before the first thread acquires it.
		To ensure bounded waiting, we write programs of the following form, in which \texttt{thread1} indicates when it has ``expressed interest in the lock``, and \texttt{thread2} counts the number of times it acquires the lock since then:
	\begin{center}
	\begin{tabular}{ll}
	\multicolumn{2}{c}{\texttt{thread1\_waiting = false;}} \\
	\multicolumn{2}{c}{\texttt{thread2\_iters = 0;~~~~~~~}} \\
	\multicolumn{2}{c}{\texttt{fork(thread1, thread2);~~}} \\
	& \\
	\texttt{thread1() \{} & \texttt{thread2() \{} \\
	\texttt{~~~~while (true) \{} & \texttt{~~~~while (true) \{} \\
	\texttt{~~~~~~~~\em lock\_express\_interest\_step();\qquad} & \texttt{~~~~~~~~\em lock\_sequence();} \\
	\texttt{~~~~~~~~thread1\_waiting = true;} & \texttt{~~~~~~~~thread2\_iters++;} \\
	\texttt{~~~~~~~~thread2\_iters = 0;} & \texttt{~~~~~~~~\em unlock\_sequence();} \\
     \texttt{~~~~~~~~\em lock\_acquire\_step();} & \texttt{~~~~\}} \\
	 \texttt{~~~~~~~~thread1\_waiting = false;} & \texttt{\}} \\
	\texttt{~~~~~~~~\em unlock\_sequence();} & \\
	\texttt{~~~~\}} & \\
	\texttt{\}} & \\
	\end{tabular}
	\end{center}
		We then set the goal statement to be \texttt{thread1\_waiting \&\& thread2\_iters = 2}. When a complete planner cannot plan for this fact, it guarantees bounded waiting for $N=2$. If a planner does find a plan, we change $2$ to some higher number until the planner fails; if no such higher number exists, bounded waiting is not satisfied.

		This setup also assumes that the lock sequence can be subdivided into the two subsequences denoted above. If there exists no such split, we say that the algorithm does not provide bounded waiting.\footnote{
		This nonexistence can be verified by enumerating all possible instructions in the lock sequence before which to put the new steps. In our test suite, we are not exhaustive about this, though it is possible.}
	\item {\bf Progress.} An algorithm that provides progress guarantees that for all $N$, with $N$ operations on the lock, there exists some $M$ number of instructions such that no execution trace longer than $M$ achieves fewer than $N$ operations. (In other words, all operations complete in finite time; there can be no livelocks or deadlocks on a single lock.)

		We could not devise a way to verify progress using the planning technology we had at hand. However, we imagine a hypothetical planner which could perform analysis on the state-space graph to provide this. In planning terminology, progress is stated as follows:
		\begin{itemize}
			\item For all reachable states $S$, there exists a plan from $S$ that acquires+releases the lock an additional time (no deadlock), and
			\item Given some $N$, there exists a finite $M$ such that all plans of length $M$ acquire+release the lock $N$ times (no livelock).
		\end{itemize}
\end{enumerate}

\subsubsection{Results}

Using test cases following the above schemes, we verified or generated counterexamples for mutual exclusion and bounded waiting for four well-known synchronisation algorithms.\footnote{
Pseudocode sketches of each of these algorithms can be found on the wikipedia articles of the same name.}

\begin{itemize}
	\item {\bf Dekker's algorithm.} Demonstrated in the test cases that start with \texttt{prob4}. We verify mutual exclusion and refute bounded waiting.
	\item {\bf Peterson's algorithm.} Demonstrated in the test cases that start with \texttt{prob7}. We verify mutual exclusion and bounded waiting.
	\item {\bf Spinlock (atomic-exchange).} Demonstrated in the test cases that start with \texttt{prob8}. We verify mutual exclusion and refute bounded waiting.
	\item {\bf Lamport's bakery algorithm (atomic-add).} Demonstrated in the test cases that start with \texttt{prob9}. We verify mutual exclusion and bounded waiting.
\end{itemize}

We also include a broken algorithm, \texttt{prob51-broken-lock.pddl}, for which we can even refute mutual exclusion (i.e., the planner can plan for \texttt{num\_in\_section == 2}).

\subsection{Compiler}

To help test our shared memory concurrency domain and to demonstrate
its generality, we built a compiler for a very simple imperative
language with standard structured programming constructs. The compiler
is fairly simple, but makes it vastly nicer to create problems for our
imperative concurrency machine domain. In Figure
\ref{fig:dekker-code}, we show part of the source program we use for
testing Dekker's algorithm. In Figure \ref{fig:dekker-asm} we show the
corresponding output problem for our domain. Clearly, the source is
much easier to work with.



\begin{figure}
\begin{center}
\begin{verbatim}
int flag0 = 0; int flag1 = 0; int turn = 0;

int num_in_section = 0;
int thread1_waiting = 0; int thread2_iters = 0;

thread0() {
    while (1) {
        flag0 = 1;
        thread2_iters = 0; thread1_waiting = 1;

        while (flag1) {
            if (turn) { /* turn != 0 */
                flag0 = 0;
                while (turn) { /* turn != 0 */
                    /* busy wait */
                }
                flag0 = 1;
            }
        }

        /* critical section */
        thread1_waiting = 0;
        num_in_section++;
        num_in_section--;

        turn = 1;
        flag0 = 0;
    }
}

thread1() { /* ELIDED */ }

main() {
    fork(thread0, thread1);
}
\end{verbatim}
\end{center}
\caption{Dekker's algorithm in our simple language}
\label{fig:dekker-code}
\end{figure}

\begin{figure}
\begin{center}
\begin{verbatim}
(define (problem dekker-loop)
    (:domain threads)
    (:objects
        n0 n1 n2 n3 n4 n5 n6 - number
        out - label
        flag0 flag1 turn num_in_section thread1_waiting thread2_iters - label

        thread00 thread01 thread02 thread03 thread04 thread05 thread06 thread07
        thread08 thread09 thread010 thread011 thread012 thread013
        thread10 thread11 thread12 thread13 thread14 thread15 thread16 thread17
        thread18 thread19 thread110 thread111
        main0 main1
        - label
    )
    (:init
        (succ n0 n1) (succ n1 n2) (succ n2 n3)
        (succ n3 n4) (succ n4 n5) (succ n5 n6)
        ; .data
        (value flag0 n0)
        (value flag1 n0)
        (value turn n0)
        (value num_in_section n0)
        (value thread1_waiting n0)
        (value thread2_iters n0)

        ; .text
        ; thread0
        (set thread00 thread01 flag0 n1)
        (set thread01 thread02 thread2_iters n0)
        (set thread02 thread03 thread1_waiting n1)
        (branch thread03 flag1 thread04 thread08)
        (branch thread04 turn thread05 thread03)
        (set thread05 thread06 flag0 n0)
        (branch thread06 turn thread06 thread07)
        (set thread07 thread03 flag0 n1)
        (set thread08 thread09 thread1_waiting n0)
        (incr thread09 thread010 num_in_section)
        (decr thread010 thread011 num_in_section)
        (set thread011 thread012 turn n1)
        (set thread012 thread00 flag0 n0)
        (exit thread013)

        ; thread1
        ; ELIDED
        ; main
        (fork main0 main1 thread00 thread10)
        (exit main1)

        (eval main0 out)
    )
    (:goal (and
            ; INSERT GOALS HERE
        )
    )
)
\end{verbatim}
\end{center}
\caption{The corresponding generated problem for Dekker's algorithm}
\label{fig:dekker-asm}
\end{figure}

